{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nimport glob\nimport requests\nimport re\nfrom bs4 import BeautifulSoup\nimport seaborn as sns\nimport nltk\nplt.style.use('ggplot')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# API Request","metadata":{}},{"cell_type":"code","source":"base_url = \"https://mastodon.social\"\naccess_token = \"Your access token\"\n\ndef search_hashtag(hashtag, limit=40, max_id=None):\n    headers = {\n        \"Authorization\": f\"Bearer {access_token}\"\n    }\n    endpoint = f\"{base_url}/api/v1/timelines/tag/{hashtag}?limit={limit}\"\n\n    if max_id:\n        endpoint += f\"&max_id={max_id}\"\n\n    response = requests.get(endpoint, headers=headers)\n\n    if response.status_code == 200:\n        return response.json()\n    else:\n        return None","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def retrieve_hashtag_posts(hashtag, max_posts=10000):\n    data = []\n    max_id = None\n\n    while len(data) < max_posts:\n        limit = min(40, max_posts - len(data))\n        hashtag_posts = search_hashtag(hashtag, limit=limit, max_id=max_id)\n\n        if not hashtag_posts:\n            break\n\n        data.extend([\n            {\n                \"Content\": post[\"content\"],\n                \"Author\": post[\"account\"][\"username\"],\n                \"Date\": post[\"created_at\"],\n            }\n            for post in hashtag_posts\n        ])\n\n        if len(hashtag_posts) < 40:\n            break\n\n        max_id = hashtag_posts[-1][\"id\"]\n\n    return data\n\nhashtag = \"Your #\"\nmax_posts = 10000\n\ndata = retrieve_hashtag_posts(hashtag, max_posts)\ndf = pd.DataFrame(data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"def preprocess_text(text):\n    # Remove URLs\n    text = re.sub(r'http\\S+', '', text)\n    \n    # Remove specific pattern\n    text = re.sub(r'class=\"ellipsis\">.*?</a>', '', text)\n    \n    # Remove HTML tags using BeautifulSoup\n    soup = BeautifulSoup(text, 'html.parser')\n    cleaned_text = soup.get_text()\n    \n    # Remove special characters and extra spaces\n    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n    \n    return cleaned_text\n\n# Apply preprocessing to the \"Content\" column\ndf[\"Cleaned_Content\"] = df[\"Content\"].apply(preprocess_text)\n\n# Display the cleaned content of the first tweet\nprint(\"Cleaned content of the first tweet:\")\nprint(df.loc[0, \"Cleaned_Content\"])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_filename = \"Your#_posts.csv\"\ndf.to_csv(csv_filename, index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sentiment Analysis","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"..Your#_posts.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NLTK**","metadata":{}},{"cell_type":"code","source":"example = df['Cleaned_Content'][42]\nprint(example)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokens = nltk.word_tokenize(example)\ntokens[:15]\ntagged = nltk.pos_tag(tokens)\ntagged[:15]\nentities = nltk.chunk.ne_chunk(tagged)\nentities.pprint()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Vaders**","metadata":{}},{"cell_type":"code","source":"from nltk.sentiment import SentimentIntensityAnalyzer\nfrom tqdm.notebook import tqdm\n\nsia = SentimentIntensityAnalyzer()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sia.polarity_scores(example)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_sentiment_analysis(df):\n    \n    df.insert(0, 'Id', range(1, 1 + len(df)))\n    \n    sia = SentimentIntensityAnalyzer()\n\n    res = {}\n    for i, row in tqdm(df.iterrows(), total=len(df)):\n        text = row['Cleaned_Content']\n        myid = row['Id']\n        res[myid] = sia.polarity_scores(text)\n\n    vaders = pd.DataFrame(res).T\n    vaders = vaders.reset_index().rename(columns={'index': 'Id'})\n    vaders = vaders.merge(df, how='left')\n    return vaders","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vaders_df = process_sentiment_analysis(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualization**","metadata":{}},{"cell_type":"code","source":"def plot_sentiment_by_year(df, year, name):\n    # Convert the \"Date\" column to datetime\n    df['Date'] = pd.to_datetime(df['Date'])\n\n    # Filter data for the specified year\n    df_year = df[df['Date'].dt.year == year]\n\n    if df_year.empty:\n        print(f\"No data available for the year {year}.\")\n        return\n\n    # Plotting\n    plt.figure(figsize=(10, 6))\n    plt.scatter(df_year['Date'], df_year['compound'], color='b', marker='o')\n    plt.title(f'Sentiment Analysis of {name}-Posts in {year}')\n    plt.xlabel('Date')\n    plt.ylabel('Compound Sentiment Score')\n    plt.xticks(rotation=45)\n    plt.grid(True)\n    plt.tight_layout()\n\n    # Display the plot\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vaders_df_2023 = plot_sentiment_by_year(vaders_df, year=2023, name=\"Your#\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_sentiment_intensity_column(dataframe):\n    conditions = [\n        (dataframe['compound'] > 0.5),\n        (dataframe['compound'] > 0.1),\n        (dataframe['compound'] > -0.1),\n        (dataframe['compound'] > -0.5)\n    ]\n    \n    choices = [2, 1, 0, -1]\n    \n    dataframe['sent_int_score'] = np.select(conditions, choices, default=-2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vaders_df_sentint = add_sentiment_intensity_column(vaders_df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_sentiment_intensity(dataframe, title_name):\n    # Calculate the average sentiment score\n    avg_sentiment = dataframe['compound'].mean()\n    \n    # Map sentiment intensity scores to labels\n    sentiment_labels = {\n        -2: \"Highly Negative\",\n        -1: \"Negative\",\n        0: \"Neutral\",\n        1: \"Positive\",\n        2: \"Highly Positive\"\n    }\n    \n    # Group data by sentiment intensity score and count occurrences\n    sentiment_counts = dataframe['sent_int_score'].value_counts().sort_index()\n    \n    # Plotting\n    plt.figure(figsize=(8, 5))\n    plt.bar(sentiment_labels.values(), sentiment_counts, color='blue')\n    plt.title('Sentiment Intensity Distribution of {}-Posts'.format(title_name))\n    plt.xlabel('Sentiment Intensity')\n    plt.ylabel('Count')\n    plt.xticks(rotation=45)\n    plt.legend()\n    plt.tight_layout()\n\n    plt.show()\n    \n    print(\"Average Compound Sentiment Score:\", avg_sentiment)\n    print(\"Total Posts:\", len(dataframe))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_sentiment_intensity(vaders_df_sentint, \"Your#\")","metadata":{},"execution_count":null,"outputs":[]}]}